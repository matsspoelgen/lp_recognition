{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file cropped_lps already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file _oof already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir cropped_lps\n",
    "!mkdir _oof\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "ccpd_base_path = 'CCPD_data/ccpd_base/'\n",
    "cropped_path = 'cropped_lps/'\n",
    "\n",
    "uncropped_images = os.listdir(ccpd_base_path)\n",
    "uncropped_images = [ccpd_base_path + img for img in uncropped_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "def extract_plate_number(plate_number):\n",
    "    chi_let = provinces[int(plate_number.split(\"_\")[0])]\n",
    "    alp_let = alphabets[int(plate_number.split(\"_\")[1])]\n",
    "    alp_num_let = plate_number.split(\"_\")[2:]\n",
    "    alp_num_let = \"\".join([ads[int(char)] for char in alp_num_let])\n",
    "    all_let = chi_let + alp_let + alp_num_let\n",
    "    return all_let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matss\\Downloads\\project\\crop_to_lp.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         cv2\u001b[39m.\u001b[39mimwrite(cropped_path \u001b[39m+\u001b[39m plate_number \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, cv2\u001b[39m.\u001b[39mcvtColor(crop, cv2\u001b[39m.\u001b[39mCOLOR_RGB2BGR))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m uncropped_images:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     detect_and_crop(image)\n",
      "\u001b[1;32mc:\\Users\\matss\\Downloads\\project\\crop_to_lp.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_and_crop\u001b[39m(image_path):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Original Image\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     ori_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     ori_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(ori_image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matss/Downloads/project/crop_to_lp.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# output name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:25\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(filename: \u001b[39mstr\u001b[39m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m cv2\u001b[39m.\u001b[39mimdecode(np\u001b[39m.\u001b[39mfromfile(filename, np\u001b[39m.\u001b[39muint8), flags)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yolo_model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "def get_crop(image, box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def detect_and_crop(image_path):\n",
    "    # Original Image\n",
    "    ori_image = cv2.imread(image_path)\n",
    "    ori_image = cv2.cvtColor(ori_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # output name\n",
    "    plate_number = image_path.split(\"-\")[4]\n",
    "\n",
    "    result = yolo_model.predict([image_path], verbose=False)[0]\n",
    "    boxes = [box.data[0][:4] for box in result.boxes]\n",
    "    num_boxes = len(boxes)\n",
    "\n",
    "    if num_boxes == 1:\n",
    "        # increase box size by \n",
    "        x1, y1, x2, y2 = boxes[0]\n",
    "        padding = (x2 - x1)* 0.1\n",
    "        box = [x1 - padding, y1 - padding, x2 + padding, y2 + padding]\n",
    "        crop = get_crop(ori_image, box)\n",
    "        cv2.imwrite(cropped_path + plate_number + \".jpg\", cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "for image in uncropped_images:\n",
    "    detect_and_crop(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
